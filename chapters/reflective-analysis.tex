This section aims to give a critical reflection of my own thoughts on the project. While many aspects of the project went well, some could have been improved if undertaken again. To aid in this analysis segments of the Gibbs reflective cycle were used to help structure this section \citep{gibbs1988learning}.

\section{Positive Aspects of the Project}
Many aspects of this project were positive, the first of which is the development of the artefact itself. Throughout the duration of this project I built a solid framework in which to train and evaluate many models and variations quickly and efficiently. When beginning the project I dedicated a lot of time to learning the various libraries involved and methods that other researchers used to carry out such evaluations, this helped significantly in building this robust artefact. The artefact can be used in the future if necessary, for further evaluations in this space or to re-apply in other projects.

Another aspect of this project that went well was the model performance itself. My expectations going into this project were that it would be unachievable to build a model as successful as other published papers. The results of the best models in the study speak for themselves and with the excellent performance metrics of the final model, I feel very accomplished having even beaten other studies model performance. This is not to say that the model performances achieved in this study are unrivalled or ground breaking, but being able to judge my results on par with others results was a success in itself.

I was also able to gain a deep understanding of machine learning, deep learning and the toolsets required to enable these. Learning the workings of libraries like Keras and TensorFlow has served me well for not only this project, but will help me in the future by being able to apply this knowledge to the industry. It also enabled me to quickly recreate other researchers models from architecture diagrams, like \cite{fitriasari2021improvement} Xception-ResNet model. Using Google Cloud Platform as a development environment was a particularly beneficial part to this project, as it saved days worth of training time by enabling me to train models in parallel, by splitting execution tasks among many virtual servers.

Finally the analysis of the models went smoothly, by devising the metrics I would use beforehand within the methodology and applying these in my evaluation allowed me to quickly judge and compare models in this study and others quickly. 

\section{Negative Aspects of the Project}
Inconsistencies of metric recording

Model improvements

Securing compute power

\section{Improvements That Could Have Been Made}
Drawing further inspiration from other COVID models

Trialing use of other pre-training methods like the CheXpert dataset

Evaluating performance of other studies models on the same dataset.